Генерация подписей к изображениям с помощью CNN-RNN (Image Captioning)

Этот проект представляет собой реализацию и сравнение моделей глубокого обучения для задачи автоматической генерации текстовых описаний (подписей) к изображениям. В основе решения лежит комбинация сверточных нейронных сетей (CNN) для извлечения визуальных признаков и рекуррентных нейронных сетей (RNN/LSTM) для генерации текстовых последовательностей.

Две архитектуры: Реализованы и сравнены две популярные архитектуры (Init-inject и Pre-inject) для интеграции визуальной и текстовой информации.

Предобученная CNN: Использование предварительно извлеченных признаков из VGG-16 для кодирования изображений.

LSTM-декодер: Применение Long Short-Term Memory (LSTM) сети для генерации подписей слово за словом.

Обучение и оценка: Полноценный пайплайн обучения и валидации модели на PyTorch, включая отслеживание метрик.

Оценка качества: Использование стандартной метрики BLEU для количественного сравнения качества сгенерированных подписей.

Реализованные архитектуры:

В соответствии с заданием, были реализованы две архитектуры, описанные в статье "Where to put the Image in an Image Caption Generator".

1. Init-inject

В этой архитектуре вектор признаков изображения используется для инициализации начального скрытого состояния LSTM-декодера. Модель получает глобальный контекст изображения один раз в самом начале, и эта информация влияет на генерацию всей подписи.

2. Pre-inject

Здесь вектор признаков изображения рассматривается как самый первый элемент последовательности, который подается на вход LSTM. Он обрабатывается как "первое слово", и полученное после него скрытое состояние используется для генерации остальной части подписи.

Набор данных

Используется популярный датасет COCO (Common Objects in Context). Для сокращения времени обработки и требований к памяти работа ведется с предварительно обработанными данными:

Признаки изображений: Извлечены из слоя fc7 модели VGG-16 и их размерность уменьшена с 4096 до 512 с помощью метода главных компонент (PCA).

        
Для запуска проекта необходимо установить зависимости и создать папку datasets и распаковать туда датасет COCO
